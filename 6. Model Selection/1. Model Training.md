# Model training

In the next notebooks, we will try different machine learning classification models, and then we will evaluate them in our test data, and select the one with the best performance. The models that we will try are:

- K Nearest Neighbors
- Linear Support Vector Classification
- Logistic Regression
- Multinomial Naive Bayes

To train these model we will use [**scikit-learn**](https://scikit-learn.org/).

For each model, we will follow the next steps:
1. Hyperparameter tuning: We decide which hyperparameters to tune, and we use a Grid Search Cross Validation to choose the ones with best accuracy.
2. Model fit: We train the model with the best hyperparameters.
3. Model performance: We compute the training and test accuracy, the classification report, and the confusion matrix. We will save these data to compare the models.

Then, we will compare the model performances and we will choose the one that we consider is the most suitable. Also, for the development of the web application, we will need that our model can predict the class probabilities. The Linear Support Vector Classification model does not have available the function predict_proba so we will need to use [CalibratedClassifierCV](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html) in this case.

