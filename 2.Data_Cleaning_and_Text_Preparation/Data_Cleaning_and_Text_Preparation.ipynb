{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43d885ab",
   "metadata": {},
   "source": [
    "# Data Cleaning and text preparation\n",
    "\n",
    "In this notebook, we explore our collected data. We deal with missing values, and then we prepare the text.\n",
    "In order to do this we clean special characters, punctuation signs, etc. Then we remove stop words and we use lemmatization.\n",
    "\n",
    "For lemmatization we use [spaCy](https://spacy.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dd8bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a9f80c",
   "metadata": {},
   "source": [
    "We load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a1cd95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/home/maggie/News_classifier/1.Data_Collection/' \n",
    "df_news=pd.read_csv(path + 'news_data.csv',encoding='utf8')\n",
    "df_news.Fecha=df_news.Fecha.apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01664d6b",
   "metadata": {},
   "source": [
    "We explore our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82a89cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26058, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7160656",
   "metadata": {},
   "source": [
    "A look at the first five rows of our data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d3ce7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Título</th>\n",
       "      <th>Link</th>\n",
       "      <th>Descripcion</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Diario</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vecinos de Cristina Kirchner colgaron una band...</td>\n",
       "      <td>https://www.clarin.com/politica/vecinos-cristi...</td>\n",
       "      <td>La pusieron en el piso de arriba de donde vive...</td>\n",
       "      <td>2021-11-09 13:41:23</td>\n",
       "      <td>Clarín</td>\n",
       "      <td>Política</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tras un año de cortocircuitos, el Gobierno rea...</td>\n",
       "      <td>https://www.clarin.com/politica/ano-cortocircu...</td>\n",
       "      <td>Volvieron a mostrarse juntos en campaña. Inten...</td>\n",
       "      <td>2021-11-09 13:07:56</td>\n",
       "      <td>Clarín</td>\n",
       "      <td>Política</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>El domingo Javier Milei tendrá su búnker en el...</td>\n",
       "      <td>https://www.clarin.com/politica/domingo-javier...</td>\n",
       "      <td>El economista liberal de la Libertad Avanza es...</td>\n",
       "      <td>2021-11-09 12:33:57</td>\n",
       "      <td>Clarín</td>\n",
       "      <td>Política</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elecciones 2021: se podrá viajar gratis todo e...</td>\n",
       "      <td>https://www.clarin.com/politica/elecciones-202...</td>\n",
       "      <td>Lo confirmó el Ministerio de Transporte. En la...</td>\n",
       "      <td>2021-11-09 11:57:30</td>\n",
       "      <td>Clarín</td>\n",
       "      <td>Política</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El drama de la inseguridad en la Provincia: se...</td>\n",
       "      <td>https://www.clarin.com/politica/drama-inseguri...</td>\n",
       "      <td>Son números oficiales de 2020. Se iniciaron 78...</td>\n",
       "      <td>2021-11-09 11:57:13</td>\n",
       "      <td>Clarín</td>\n",
       "      <td>Política</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Título  \\\n",
       "0  Vecinos de Cristina Kirchner colgaron una band...   \n",
       "1  Tras un año de cortocircuitos, el Gobierno rea...   \n",
       "2  El domingo Javier Milei tendrá su búnker en el...   \n",
       "3  Elecciones 2021: se podrá viajar gratis todo e...   \n",
       "4  El drama de la inseguridad en la Provincia: se...   \n",
       "\n",
       "                                                Link  \\\n",
       "0  https://www.clarin.com/politica/vecinos-cristi...   \n",
       "1  https://www.clarin.com/politica/ano-cortocircu...   \n",
       "2  https://www.clarin.com/politica/domingo-javier...   \n",
       "3  https://www.clarin.com/politica/elecciones-202...   \n",
       "4  https://www.clarin.com/politica/drama-inseguri...   \n",
       "\n",
       "                                         Descripcion               Fecha  \\\n",
       "0  La pusieron en el piso de arriba de donde vive... 2021-11-09 13:41:23   \n",
       "1  Volvieron a mostrarse juntos en campaña. Inten... 2021-11-09 13:07:56   \n",
       "2  El economista liberal de la Libertad Avanza es... 2021-11-09 12:33:57   \n",
       "3  Lo confirmó el Ministerio de Transporte. En la... 2021-11-09 11:57:30   \n",
       "4  Son números oficiales de 2020. Se iniciaron 78... 2021-11-09 11:57:13   \n",
       "\n",
       "   Diario     Label  \n",
       "0  Clarín  Política  \n",
       "1  Clarín  Política  \n",
       "2  Clarín  Política  \n",
       "3  Clarín  Política  \n",
       "4  Clarín  Política  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22887a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26058 entries, 0 to 26057\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   Título       26056 non-null  object        \n",
      " 1   Link         26049 non-null  object        \n",
      " 2   Descripcion  24184 non-null  object        \n",
      " 3   Fecha        26058 non-null  datetime64[ns]\n",
      " 4   Diario       26058 non-null  object        \n",
      " 5   Label        26058 non-null  object        \n",
      "dtypes: datetime64[ns](1), object(5)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_news.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2db7b88",
   "metadata": {},
   "source": [
    "We noticed that some descriptions are missing. In this case, we only work with the title. We fill in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "412cfa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news.Descripcion = df_news.Descripcion.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e576a3",
   "metadata": {},
   "source": [
    "We also noticed that very few news do not have a title or URL link. We remove them from our data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1fe1efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news=df_news.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e36794",
   "metadata": {},
   "source": [
    "We check that there are no duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de162ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    26049\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.duplicated().value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34a6c44",
   "metadata": {},
   "source": [
    "We create a new column, joining title and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "decb633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news['Texto']=df_news['Título'] +'. '+ df_news['Descripcion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f5c0ff",
   "metadata": {},
   "source": [
    "### Text cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8786b350",
   "metadata": {},
   "source": [
    "By manual inspection, we see that all the news articles from the newspaper \"Perfil\" end with \"leer más'. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b19c91fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p><img src=\"https://fotos.perfil.com/2021/11/09/trim/540/304/javier-milei-1266604.jpg\" alt=\"Javier Milei\" /></p>El candidato a diputado cruzó duramente al ministro de Seguridad a raíz del caso del kiosquero asesinado en Ramos Mejía. <a href=\"https://www.perfil.com/noticias/politica/milei-a-anibal-fernandez-por-que-sos-tan-h-de-p.phtml\">Leer más</a>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news[df_news.Diario=='Perfil'].Descripcion.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e557cece",
   "metadata": {},
   "source": [
    "We create a function that removes that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "251582b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_leer_mas(text):\n",
    "    try:\n",
    "        if text.split()[-2]=='leer' and text.split()[-1]=='más':\n",
    "            return text[:-9]\n",
    "        else:\n",
    "            return text\n",
    "    except:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d3756a",
   "metadata": {},
   "source": [
    "Also, we create a function that removes HTML tags and some special entities that appear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1bd21ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    \"\"\"Remove html tags from a string\"\"\"\n",
    "    clean = re.compile('<.*?>')\n",
    "    #some special entities, see https://www.htmlhelp.com/reference/html40/entities/special.html\n",
    "    # to know what is included, for example: df_news[df_news['Texto'].str.contains('quot')]['Texto']\n",
    "    pattern = re.compile(\"|\".join(['&amp','ndash','mdash','lsquo','rsquo','ldquo','rdquo']))\n",
    "    text = pattern.sub('', text)\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeec2def",
   "metadata": {},
   "source": [
    "We also have some symbols for the accent marks. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c831fef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Otra pelea m&#225;s del Gobierno con el peronismo de C&#243;rdoba. \\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.Texto[298]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4715952e",
   "metadata": {},
   "source": [
    "We create a dictionary to replace these symbols into readable accent marks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0af18f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "tildes={\"&#225;\":'á',\"&#233;\":'e',\"&#237;\":'í',\"&#243;\":'ó',\"&#250;\":'ú'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229dc178",
   "metadata": {},
   "source": [
    "Now, we create our text cleaning function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84476bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    #remove htlm tags\n",
    "    text=remove_html_tags(text)\n",
    "    #make text lowercase\n",
    "    text = text.lower()\n",
    "    #correct accent marks\n",
    "    for key in tildes.keys():\n",
    "        text = text.replace(key, tildes[key])\n",
    "    #remove punctuation \n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    #remove some non-ASCII characters, see https://www.codetable.net/asciikeycodes\n",
    "    text=re.sub(r'[\\x7f-\\x9f]','',text) \n",
    "    #this is a white space\n",
    "    text=re.sub(r'[\\xa0]',' ', text)\n",
    "    text=re.sub(r'[\\xa1-\\xbf]','',text) \n",
    "    #remove words containing numbers\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    #remove some additional punctuation that was missed the first time around.\n",
    "    text = re.sub('[‘’“”…«»–]', '', text)\n",
    "    #remove linespaces\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    #remove leading and trailing whitespaces\n",
    "    text = re.sub('\\s+', ' ',text).strip()\n",
    "    #remove \"leer mas\" from news from perfil\n",
    "    text=remove_leer_mas(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beb503a",
   "metadata": {},
   "source": [
    "We create a new column with the clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75898db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news['Texto_clean'] = df_news.Texto.apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f855e9e",
   "metadata": {},
   "source": [
    "### Lemmatization and removal of stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de62fad0",
   "metadata": {},
   "source": [
    "We load Spanish stopwords from https://countwordsfree.com/stopwords/spanish modified by stopwords.py. The last one is a script that adds to our stopwords the lemmatized form of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b9b1c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = open(\"stopwords_spanish.txt\", \"r\")\n",
    "stopwords = my_file.read()\n",
    "stopwords  = stopwords.split(\"\\n\")\n",
    "my_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7a61d9",
   "metadata": {},
   "source": [
    "We use spacy for lemmatization. See the [Spanish models](https://spacy.io/models/es)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30a7cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c3eebd",
   "metadata": {},
   "source": [
    "We previously checked that lemmatization works poorly for some words. By manual inspection, we add some of them into these objects. We want to keep the words in the list words_with_bad_lemmatization in that way and we want to change the keys in the dictionary words_with_bad_lemmatization_2 for the values that appear there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "933fba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_with_bad_lemmatization=['lucas','coronavirus','efemérides','argentina','wanda','drive','core','sosa','matías']\n",
    "words_with_bad_lemmatization_2={'argentino':'argentina','argentinos':'argentina','ruso':'rusia',\n",
    "                                'rusa':'rusia','rusos':'rusia','rusas':'rusia','ucraniano':'ucrania','ucraniana':\n",
    "                               'ucrania','ucranianas':'ucrania','ucranianos':'ucrania','francés':'francia','actriz':'actor',\n",
    "                               'actrices':'actor'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0037a1",
   "metadata": {},
   "source": [
    "We iterate through every row in the data frame in order to lemmatize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da96a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = len(df_news)\n",
    "lemmatized_text_list= []\n",
    "\n",
    "for row in range(rows):\n",
    "    # we create an empty list containing lemmatized words\n",
    "    lemmatized_words = []\n",
    "    # save the text and its words into an object\n",
    "    texto=nlp(df_news.loc[row]['Texto_clean'])\n",
    "    for palabra in texto:\n",
    "        lemma=palabra.lemma_\n",
    "        for word in lemma.split(): #some lemmas have two words, ex. \"mostrarse\" into \"mostrar\" and \"él\"\n",
    "            if word not in stopwords and palabra.text not in words_with_bad_lemmatization and palabra.text not in words_with_bad_lemmatization_2.keys():\n",
    "                lemmatized_words.append(word)\n",
    "            elif palabra.text in words_with_bad_lemmatization:\n",
    "                lemmatized_words.append(palabra.text) \n",
    "            elif palabra.text in words_with_bad_lemmatization_2.keys():\n",
    "                lemmatized_words.append(words_with_bad_lemmatization_2[palabra.text])\n",
    "    # join the list\n",
    "    lemmatized_text = \" \".join(lemmatized_words)\n",
    "    #There are very short news articles that after cleaning they become empty. We remove these rows then from the data frame.\n",
    "    if lemmatized_text=='':\n",
    "        df_news.drop(row, inplace=True)\n",
    "        df_news.reset_index(drop=True)\n",
    "    else:\n",
    "        # Append to the list containing the texts\n",
    "        lemmatized_text_list.append(lemmatized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7b90db",
   "metadata": {},
   "source": [
    "We create a new column with the lemmatized clean text and without stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7fd0766",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news['Texto_clean_lemmatized_and_stopwords']  = lemmatized_text_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fbf1a4",
   "metadata": {},
   "source": [
    "As an example, we look at one article, in the original form, after the text cleaning, and after lemmatization and removal of stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ab429bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Por qué el virus Nipah puede convertirse en \"la peor pandemia que la humanidad haya enfrentado\". <p><img src=\"https://fotos.perfil.com/2021/09/13/trim/540/304/nipah-kerala-india-1230332.jpg\" alt=\"nipah kerala india\" /></p>Expertos creen que, debido a la alta letalidad que tiene el virus NiV, una nueva cepa \"podría representar la peor pandemia\" que haya vivido la humanidad. El estado indio de Kerala observa con atención el nuevo brote. <a href=\"https://www.perfil.com/noticias/ciencia/por-que-el-virus-nipah-puede-convertirse-en-la-peor-pandemia-que-la-humanidad-haya-enfrentado.phtml\">Leer más</a>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.Texto.loc[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0d44854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'por qué el virus nipah puede convertirse en la peor pandemia que la humanidad haya enfrentado expertos creen que debido a la alta letalidad que tiene el virus niv una nueva cepa podría representar la peor pandemia que haya vivido la humanidad el estado indio de kerala observa con atención el nuevo brote'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.Texto_clean.loc[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "936747a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'virus nipah convertir peor pandemia humanidad enfrentar experto alto letalidad virus niv cepa representar peor pandemia vivir humanidad indio kerala observar atención brote'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.Texto_clean_lemmatized_and_stopwords.loc[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3180d7a7",
   "metadata": {},
   "source": [
    "We save the modified data in a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cd7e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news.to_csv('clean_data.csv',index=False)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
